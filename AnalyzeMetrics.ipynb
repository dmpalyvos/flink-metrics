{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import requests\n",
    "import time\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from matplotlib import lines, markers\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = 'http://localhost:8081'\n",
    "SAMPLING_FREQ_SEC = 1\n",
    "DURATION_SEC = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitComponent(component, pattern):\n",
    "    m = METRIC_PATTERN.match(component)\n",
    "    if m:\n",
    "        mdict = matchDict(m)\n",
    "        return mdict['instance'], mdict['component'], mdict['metric']\n",
    "    raise Exception(f'Failed to match {component}!')\n",
    "    \n",
    "def getTaskManagers():\n",
    "    return requests.get(f'{BASE_URL}/taskmanagers').json()['taskmanagers']\n",
    "    \n",
    "def getAvailableTaskManagerMetrics():\n",
    "    return [metric['id'] for metric in requests.get(f'{BASE_URL}/taskmanagers/metrics').json()]\n",
    "\n",
    "def getTaskManagerMetrics(tmID, metrics):\n",
    "    metricString = ','.join(metrics)\n",
    "    return requests.get(f'{BASE_URL}/taskmanagers/{tmID}/metrics', params={'get': metricString}).json()\n",
    "    \n",
    "def getAvailableVertexMetrics(jobID, vertexID):\n",
    "    return [metric['id'] for metric in requests.get(f'{BASE_URL}/jobs/{jobID}/vertices/{vertexID}/metrics').json()]\n",
    "\n",
    "def getJobMetrics(jobID, vertexID, metrics, maxRequestLength=40):\n",
    "    def rawGetJobMetrics(jobID, vertexID, metrics):\n",
    "        metricString = ','.join(metrics)\n",
    "        return requests.get(f'{BASE_URL}/jobs/{jobID}/vertices/{vertexID}/metrics', params={'get': metricString}).json()\n",
    "    completeJSON = []\n",
    "    # Split metric requests so that the request string does not become too long\n",
    "    for i in range(0, len(metrics), maxRequestLength):\n",
    "        partialMetrics = metrics[i:i+maxRequestLength]\n",
    "        completeJSON += rawGetJobMetrics(jobID, vertexID, partialMetrics)\n",
    "    return completeJSON\n",
    "\n",
    "def matchDict(match):\n",
    "    d = defaultdict(lambda: 'DEFAULT')\n",
    "    matchDict = match.groupdict()\n",
    "    d.update(matchDict)\n",
    "    return d\n",
    "\n",
    "def plotAggregatedInstances(df, ax, mint):\n",
    "    # Fixme: Cleanup\n",
    "    df.t -= mint\n",
    "    markerstyles = list(markers.MarkerStyle.markers.keys())\n",
    "    aggregated = df.groupby(['t', 'vertex', 'component']).aggregate({'value': [np.mean, np.std]})\n",
    "    for i, (name, group) in enumerate(aggregated.groupby(level=['vertex', 'component'])):\n",
    "        data = group.reset_index()\n",
    "        ax.plot(data.t, data.value['mean'], alpha=.7, label=name[0][:5] + '_' + name[1][:15], \n",
    "                marker=markerstyles[i % len(markerstyles)], markevery=20, markersize=5)\n",
    "        ax.fill_between(data.t, data.value['mean'] - data.value['std']/2, data.value['mean'] + data.value['std']/2, alpha=.3)\n",
    "        \n",
    "def plotTaskManagerMetrics(df, ax, mint):\n",
    "    # Fixme: Cleanup\n",
    "    df.t -= mint\n",
    "    markerstyles = list(markers.MarkerStyle.markers.keys())\n",
    "    aggregated = df.groupby(['t', 'tm', 'metric']).aggregate({'value': [np.mean, np.std]})\n",
    "    for i, (name, group) in enumerate(aggregated.groupby(level=['tm'])):\n",
    "        data = group.reset_index()\n",
    "        ax.plot(data.t, data.value['mean'], alpha=.7, label=name[:5],\n",
    "                marker=markerstyles[i % len(markerstyles)], markevery=20, markersize=5)\n",
    "        ax.fill_between(data.t, data.value['mean'] - data.value['std']/2, data.value['mean'] + data.value['std']/2, alpha=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC_PATTERN = None\n",
    "METRICS = None \n",
    "TM_METRICS = None\n",
    "PLOTTED_METRIC = None\n",
    "OPERATOR_METRIC_PATTERN = re.compile('^(?P<instance>\\d+)\\.(?P<component>.+)\\.(?P<metric>.+)?$')\n",
    "CHAIN_METRIC_PATTERN = re.compile('^(?P<instance>\\d+)\\.(?P<metric>[^\\.]+)$')\n",
    "\n",
    "#FIXME: Convert to function\n",
    "jobs = requests.get(f'{BASE_URL}/jobs').json()['jobs']\n",
    "taskManagers = getTaskManagers()\n",
    "runningJobs = [job for job in jobs if job['status'] == 'RUNNING']\n",
    "assert len(runningJobs) == 1, 'Toolkit can only work with exactly one running job!'\n",
    "jobID = runningJobs[0]['id']\n",
    "\n",
    "jobInfo = requests.get(f'{BASE_URL}/jobs/{jobID}').json()\n",
    "jobName = jobInfo['name']\n",
    "vertices = jobInfo['vertices']\n",
    "\n",
    "print(f'Selected job: {jobName} ({jobID})')\n",
    "\n",
    "operatorMetrics = set()\n",
    "chainMetrics = set()\n",
    "metricRequests = {}\n",
    "vertexIndex = []\n",
    "\n",
    "for vertex in vertices:\n",
    "    # Pattern that captures the metric name\n",
    "    # and matches only for metrics that apply to operators\n",
    "    # i.e., instanceNo.opereatorName.metricName\n",
    "    vertexIndex.append((vertex['id'], vertex['name']))\n",
    "    availableMetrics = getAvailableVertexMetrics(jobID, vertex['id'])\n",
    "    for metric in availableMetrics:\n",
    "        m = OPERATOR_METRIC_PATTERN.match(metric)\n",
    "        if m:\n",
    "            operatorMetrics.add(m.group('metric'))\n",
    "            continue\n",
    "        m = CHAIN_METRIC_PATTERN.match(metric)\n",
    "        if m:\n",
    "            chainMetrics.add(m.group('metric'))\n",
    "            continue\n",
    "        raise Exception(f'Failed to match {metric}')\n",
    "\n",
    "def selectPlottedMetric(metric):\n",
    "    global PLOTTED_METRIC\n",
    "    PLOTTED_METRIC = metric\n",
    "\n",
    "def retrieveMetrics(metrics):\n",
    "    global METRICS\n",
    "    METRICS = metrics\n",
    "    for vertex in vertices:\n",
    "        vertexID = vertex['id']\n",
    "        availableMetrics = getAvailableVertexMetrics(jobID, vertexID)\n",
    "        selectedMetrics = []\n",
    "        for metric in availableMetrics:\n",
    "            m = METRIC_PATTERN.match(metric)\n",
    "            if m and m.group('metric') in METRICS:\n",
    "                selectedMetrics.append(metric)\n",
    "        metricRequests[vertexID] = selectedMetrics\n",
    "        print(f'{len(selectedMetrics)} metrics for {vertexID}')\n",
    "\n",
    "@interact(metricLevel={'operator': (operatorMetrics, OPERATOR_METRIC_PATTERN), 'chain': (chainMetrics, CHAIN_METRIC_PATTERN)})\n",
    "def selectMetrics(metricLevel):\n",
    "    global METRIC_PATTERN\n",
    "    METRIC_PATTERN = metricLevel[1]\n",
    "    interact(retrieveMetrics, metrics=widgets.SelectMultiple(options=metricLevel[0]))\n",
    "    \n",
    "@interact(metrics=widgets.SelectMultiple(description='tmMetrics', options=getAvailableTaskManagerMetrics()))\n",
    "def selectTaskManagerMetrics(metrics):\n",
    "    global TM_METRICS\n",
    "    TM_METRICS = metrics\n",
    "    \n",
    "\n",
    "    \n",
    "# FIXME: Rename to something meaningful    \n",
    "records = pd.DataFrame(columns=['t', 'vertex', 'component', 'instance', 'metric', 'value'])\n",
    "records['t'] = records['t'].astype(int)\n",
    "records['value'] = records['value'].astype(float)\n",
    "\n",
    "tmData = pd.DataFrame(columns=['t', 'tm', 'metric', 'value'])\n",
    "tmData['t'] = tmData['t'].astype(int)\n",
    "tmData['value'] = tmData['value'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Vertex Index\n",
    "for (vertexID, vertexName) in vertexIndex:\n",
    "    print(vertexID, '\\n', vertexName.replace(' -> ', '\\n').strip(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook\n",
    "\n",
    "#FIXME: Clean up len sums\n",
    "fig, axes = plt.subplots(figsize=(8, 4*(len(METRICS)+len(TM_METRICS))), nrows=len(METRICS)+len(TM_METRICS), sharex=True)\n",
    "plt.ion()\n",
    "fig.show()\n",
    "fig.canvas.draw()\n",
    "\n",
    "start = time.time()\n",
    "currentTime = time.time()\n",
    "while currentTime - start < DURATION_SEC:\n",
    "    for vertex in vertices:\n",
    "        vertexID = vertex['id']\n",
    "        metricValues = getJobMetrics(jobID, vertexID, metricRequests[vertexID])\n",
    "        for metric in metricValues:\n",
    "            componentInstance, componentName, baseMetric  = splitComponent(metric['id'], METRIC_PATTERN)\n",
    "            records = records.append({'t': int(currentTime), 'vertex': vertexID, 'component': componentName, 'instance': componentInstance, 'metric': baseMetric, 'value': float(metric['value'])}, ignore_index=True)\n",
    "    for tm in taskManagers:\n",
    "        metricValues = getTaskManagerMetrics(tm['id'], TM_METRICS)\n",
    "        for metric in metricValues:\n",
    "            tmData = tmData.append({'t': int(currentTime), 'tm': tm['id'], 'metric': metric['id'], 'value': float(metric['value'])}, ignore_index=True)\n",
    "    \n",
    "    for i, plottedMetric in enumerate(METRICS):\n",
    "        print(axes)\n",
    "        ax = axes[i]\n",
    "        ax.clear()\n",
    "        plotAggregatedInstances(records[records.metric == plottedMetric], ax, start)\n",
    "        ax.legend()\n",
    "        ax.set(xlabel='sec', title=plottedMetric)\n",
    "    \n",
    "    for i, plottedMetric in enumerate(TM_METRICS):\n",
    "        ax = axes[i+len(METRICS)]\n",
    "        ax.clear()\n",
    "        plotTaskManagerMetrics(tmData[tmData.metric == plottedMetric], ax, start)\n",
    "        ax.legend()\n",
    "        ax.set(xlabel='sec', title=plottedMetric)\n",
    "        \n",
    "    fig.canvas.draw()\n",
    "    currentTime = time.time()\n",
    "    time.sleep(SAMPLING_FREQ_SEC)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToRelativeChange(df):\n",
    "    df['value'] /= df['value'].iloc[0]\n",
    "    return df\n",
    "\n",
    "relativeChange = records.groupby(['vertex', 'instance', 'component']).apply(convertToRelativeChange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plotAggregatedInstances(relativeChange, ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
