{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import requests\n",
    "import time\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from matplotlib import lines, markers\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "plt.style.use('ggplot')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = 'http://localhost:8081'\n",
    "SAMPLING_FREQ_SEC = 1\n",
    "DURATION_SEC = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitComponent(component, pattern):\n",
    "    m = METRIC_PATTERN.match(component)\n",
    "    if m:\n",
    "        mdict = matchDict(m)\n",
    "        return mdict['instance'], mdict['component'], mdict['metric']\n",
    "    raise Exception(f'Failed to match {component}!')\n",
    "\n",
    "def getAvailableVertexMetrics(jobID, vertexID):\n",
    "    return requests.get(f'{BASE_URL}/jobs/{jobID}/vertices/{vertexID}/metrics').json()\n",
    "\n",
    "def getMetrics(jobID, vertexID, metrics, maxRequestLength=40):\n",
    "    def rawGetMetrics(jobID, vertexID, metrics):\n",
    "        metricString = ','.join(metrics)\n",
    "        return requests.get(f'{BASE_URL}/jobs/{jobID}/vertices/{vertexID}/metrics', params={'get': metricString}).json()\n",
    "    completeJSON = []\n",
    "    # Split metric requests so that the request string does not become too long\n",
    "    for i in range(0, len(metrics), maxRequestLength):\n",
    "        partialMetrics = metrics[i:i+maxRequestLength]\n",
    "        completeJSON += rawGetMetrics(jobID, vertexID, partialMetrics)\n",
    "    return completeJSON\n",
    "\n",
    "def matchDict(match):\n",
    "    d = defaultdict(lambda: 'DEFAULT')\n",
    "    matchDict = match.groupdict()\n",
    "    d.update(matchDict)\n",
    "    return d\n",
    "\n",
    "def plotAggregatedInstances(df, ax):\n",
    "    markerstyles = list(markers.MarkerStyle.markers.keys())\n",
    "    aggregated = df.groupby(['t', 'vertex', 'component']).aggregate({'value': [np.mean, np.std]})\n",
    "    for i, (name, group) in enumerate(aggregated.groupby(level=['vertex', 'component'])):\n",
    "        data = group.reset_index()\n",
    "        data.t -= data.t.min()\n",
    "        ax.plot(data.t, data.value['mean'], alpha=.7, label=name[0][:5] + '_' + name[1][:15], \n",
    "                marker=markerstyles[i % len(markerstyles)], markevery=20, markersize=5)\n",
    "        ax.fill_between(data.t, data.value['mean'] - data.value['std']/2, data.value['mean'] + data.value['std']/2, alpha=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC_PATTERN = None\n",
    "METRICS = None \n",
    "PLOTTED_METRIC = None\n",
    "OPERATOR_METRIC_PATTERN = re.compile('^(?P<instance>\\d+)\\.(?P<component>.+)\\.(?P<metric>.+)$')\n",
    "CHAIN_METRIC_PATTERN = re.compile('^(?P<instance>\\d+)\\.(?P<metric>[^\\.]+)$')\n",
    "\n",
    "jobs = requests.get(f'{BASE_URL}/jobs').json()['jobs']\n",
    "runningJobs = [job for job in jobs if job['status'] == 'RUNNING']\n",
    "assert len(runningJobs) == 1, 'Toolkit can only work with exactly one running job!'\n",
    "jobID = runningJobs[0]['id']\n",
    "\n",
    "jobInfo = requests.get(f'{BASE_URL}/jobs/{jobID}').json()\n",
    "jobName = jobInfo['name']\n",
    "vertices = jobInfo['vertices']\n",
    "\n",
    "print(f'Selected job: {jobName} ({jobID})')\n",
    "\n",
    "operatorMetrics = set()\n",
    "chainMetrics = set()\n",
    "metricRequests = {}\n",
    "vertexIndex = []\n",
    "\n",
    "for vertex in vertices:\n",
    "    # Pattern that captures the metric name\n",
    "    # and matches only for metrics that apply to operators\n",
    "    # i.e., instanceNo.opereatorName.metricName\n",
    "    vertexIndex.append((vertex['id'], vertex['name']))\n",
    "    availableMetrics = getAvailableVertexMetrics(jobID, vertex['id'])\n",
    "    for metric in availableMetrics:\n",
    "        m = OPERATOR_METRIC_PATTERN.match(metric['id'])\n",
    "        if m:\n",
    "            operatorMetrics.add(m.group('metric'))\n",
    "            continue\n",
    "        m = CHAIN_METRIC_PATTERN.match(metric['id'])\n",
    "        if m:\n",
    "            chainMetrics.add(m.group('metric'))\n",
    "            continue\n",
    "        raise Exception(f'Failed to match {metric}')\n",
    "\n",
    "def selectPlottedMetric(metric):\n",
    "    global PLOTTED_METRIC\n",
    "    PLOTTED_METRIC = metric\n",
    "\n",
    "def retrieveMetrics(metrics):\n",
    "    global METRICS\n",
    "    METRICS = metrics\n",
    "    for vertex in vertices:\n",
    "        vertexID = vertex['id']\n",
    "        availableMetrics = getAvailableVertexMetrics(jobID, vertexID)\n",
    "        selectedMetrics = []\n",
    "        for metric in availableMetrics:\n",
    "            m = METRIC_PATTERN.match(metric['id'])\n",
    "            if m and m.group('metric') in METRICS:\n",
    "                selectedMetrics.append(metric['id'])\n",
    "        metricRequests[vertexID] = selectedMetrics\n",
    "        print(f'{len(selectedMetrics)} metrics for {vertexID}')\n",
    "\n",
    "@interact(metricLevel={'operator': (operatorMetrics, OPERATOR_METRIC_PATTERN), 'chain': (chainMetrics, CHAIN_METRIC_PATTERN)})\n",
    "def selectMetrics(metricLevel):\n",
    "    global METRIC_PATTERN\n",
    "    METRIC_PATTERN = metricLevel[1]\n",
    "    interact(retrieveMetrics, metrics=widgets.SelectMultiple(options=metricLevel[0]))\n",
    "    \n",
    "records = pd.DataFrame(columns=['t', 'vertex', 'component', 'instance', 'metric', 'value'])\n",
    "records['t'] = records['t'].astype(float)\n",
    "records['value'] = records['value'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Vertex Index\n",
    "for (vertexID, vertexName) in vertexIndex:\n",
    "    print(vertexID, '\\n', vertexName.replace(' -> ', '\\n').strip(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook\n",
    "    \n",
    "fig, axes = plt.subplots(figsize=(8, 4*len(METRICS)), nrows=len(METRICS))\n",
    "plt.ion()\n",
    "fig.show()\n",
    "fig.canvas.draw()\n",
    "\n",
    "start = time.time()\n",
    "currentTime = time.time()\n",
    "while currentTime - start < DURATION_SEC:\n",
    "    for vertex in vertices:\n",
    "        vertexID = vertex['id']\n",
    "        metricValues = getMetrics(jobID, vertexID, metricRequests[vertexID])\n",
    "        for metric in metricValues:\n",
    "            componentInstance, componentName, baseMetric  = splitComponent(metric['id'], METRIC_PATTERN)\n",
    "            records = records.append({'t': float(currentTime), 'vertex': vertexID, 'component': componentName, 'instance': componentInstance, 'metric': baseMetric, 'value': float(metric['value'])}, ignore_index=True)\n",
    "    for i, plottedMetric in enumerate(METRICS):\n",
    "        ax = axes[i]\n",
    "        ax.clear()\n",
    "        plotAggregatedInstances(records[records.metric == plottedMetric], ax)\n",
    "        ax.legend()\n",
    "        ax.set(xlabel='sec', title=plottedMetric)\n",
    "    fig.canvas.draw()\n",
    "    currentTime = time.time()\n",
    "    time.sleep(SAMPLING_FREQ_SEC)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToRelativeChange(df):\n",
    "    df['value'] /= df['value'].iloc[0]\n",
    "    return df\n",
    "\n",
    "relativeChange = records.groupby(['vertex', 'instance', 'component']).apply(convertToRelativeChange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plotAggregatedInstances(relativeChange, ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
